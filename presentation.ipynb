{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "greenatom.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcnqUM3Ky34u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import tqdm\n",
        "from importlib import reload\n",
        "\n",
        "from torchtext import datasets\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRoxKe0p2T6L",
        "colab_type": "text"
      },
      "source": [
        "#### Custom imports and download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOJhx4XGIN-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz && tar -xf aclImdb_v1.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQoG_qZKzBy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/zemerov/greenatom_assignment.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WKDZ1_F14zo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import greenatom_assignment.classifier.preproc as preproc\n",
        "import greenatom_assignment.classifier.models as models\n",
        "import greenatom_assignment.classifier.utils as utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDwJdlpufgcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd greenatom_assignment && git pull\n",
        "\n",
        "preproc = reload(preproc)\n",
        "models = reload(models)\n",
        "utils = reload(utils)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6HdnBOjAFK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls  # You have to see aclImdb directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5OcpnnqIZcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = preproc.ManualTokenizer()\n",
        "\n",
        "train = []\n",
        "test = []\n",
        "\n",
        "for current_dir in ['aclImdb/train/pos/', 'aclImdb/train/neg/']:\n",
        "    for text, score in tokenizer.get_tokens_and_score(current_dir):\n",
        "        train.append((text, score))\n",
        "\n",
        "for current_dir in ['aclImdb/test/pos/', 'aclImdb/test/neg/']:\n",
        "    for text, score in tokenizer.get_tokens_and_score(current_dir):\n",
        "        test.append((text, score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj7jRNz-Jnv-",
        "colab_type": "text"
      },
      "source": [
        "### Build token mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRad-XnhKWuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_train = np.array(train)\n",
        "np_test = np.array(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaYJziyPJNKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = preproc.Vocabulary(special_tokens=['END', 'BEGIN', \"PAD\", 'UNK'])\n",
        "\n",
        "vocab.fit(np.concatenate([np_train[:, 0], np_test[:, 0]]), min_count=7)\n",
        "\n",
        "print(\"vocab size:\", len(vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCdE0_rGMWPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab.counter.most_common(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz-u6F4eaG-1",
        "colab_type": "text"
      },
      "source": [
        "### Create dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcLl3MMjNRJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = utils.Dataset(train, vocab, overfit_size=1200)\n",
        "test_dataset = utils.Dataset(test, vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ioh62RRvZ285",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "PAD_TOKEN = train_dataset.vocab([['PAD']])[0][0]\n",
        "\n",
        "print('PAD TOKEN {}; BATCH SIZE {}'.format(PAD_TOKEN, BATCH_SIZE))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=utils.Padder(pad_symbol=PAD_TOKEN))\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=utils.Padder(pad_symbol=PAD_TOKEN))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5HrlSwOae_A",
        "colab_type": "text"
      },
      "source": [
        "### Train models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L5gm8w2aXM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 256\n",
        "hidden_size = 128\n",
        "lr = 10e-3\n",
        "\n",
        "num_epoch = 3\n",
        "batch_size = 64\n",
        "device = 'cuda'\n",
        "\n",
        "model = models.CNN(len(vocab.i2t), embedding_dim, [3, 4, 5],  hidden_size).to(device)\n",
        "#model = GRU(len(vocab.i2t), embedding_dim, hidden_size, dropout=0.5).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.NLLLoss(ignore_index=PAD_TOKEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN9J7qtmompw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "epochs = 3\n",
        "val_losses = []\n",
        "epoch_losses = []\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    model.train() \n",
        "    cnt = 0\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds, _ = model(x)\n",
        "        #print(preds.shape, h.shape, y.shape)\n",
        "        loss = criterion(preds, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if not np.isnan(loss.item()):\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        if cnt % 50 == 0:\n",
        "          print('current loss on iter {}'.format(cnt), loss.item() / batch_size)\n",
        "        cnt += 1\n",
        "    \n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    \n",
        "    epoch_losses.append(epoch_loss)\n",
        "    \n",
        "    val_loss = 0.0\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for x, y in test_loader:\n",
        "        with torch.no_grad():\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            \n",
        "            preds, _ = model(x)\n",
        "            loss = criterion(preds, y)\n",
        "            if not np.isnan(loss.item()):\n",
        "                val_loss += loss.item()\n",
        "        \n",
        "    val_loss /= len(test_dataset)\n",
        "    val_losses.append(val_loss)\n",
        "    \n",
        "    print('Epoch: {}, Training Loss: {}, Validation Loss: {}'.format(epoch, epoch_loss, val_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d-jJwVAtQSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_metrics(pred, real):\n",
        "    tp = (pred[real == 1] == 1).sum()\n",
        "    fp = (pred[real == 0] == 1).sum()\n",
        "    fn = (pred[real == 1] == 0).sum()\n",
        "\n",
        "    accuracy = (pred == real).sum() / real.shape[0]\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    \n",
        "    return accuracy, precision, recall, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4vABYZbqvz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted = np.array([])\n",
        "real = np.array([])\n",
        "\n",
        "for x, y in test_loader:\n",
        "    with torch.no_grad():\n",
        "        x = x.to(device)\n",
        "            \n",
        "        preds, _ = model(x)\n",
        "        predicted = np.concatenate([predicted, preds.cpu().detach().numpy().argmax(axis=1) + 1])\n",
        "        real = np.concatenate([real, y.numpy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhrQO_Jkp6VC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "plt.rcParams.update({'font.size': 22})\n",
        "\n",
        "points = np.arange(1, len(val_losses) + 1)\n",
        "plt.plot(points, val_losses)\n",
        "plt.plot(points, epoch_losses)\n",
        "\n",
        "plt.title('GRU train error')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "plt.legend(['Test dataset', 'Train_dataset'])\n",
        "plt.grid(linestyle='-', linewidth=1)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS9RXGRYnDnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Accuracy {} \\nPrecision {}\\nRecall {}\\nF1 {}\".format(*calculate_metrics(predicted > 6, real > 6)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qojPDWqXczRG",
        "colab_type": "text"
      },
      "source": [
        "### Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDDf43sQc4N1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#torch.save(model, 'greenatom_assignment/classifier/gru.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}