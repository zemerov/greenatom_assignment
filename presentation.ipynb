{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "greenatom.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcnqUM3Ky34u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import spacy\n",
        "from spacy.symbols import ORTH\n",
        "import string\n",
        "import io\n",
        "import os\n",
        "import collections\n",
        "import itertools\n",
        "import tqdm\n",
        "from importlib import reload\n",
        "\n",
        "from torchtext import datasets\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRoxKe0p2T6L",
        "colab_type": "text"
      },
      "source": [
        "#### Custom imports and download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOJhx4XGIN-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "48d98789-7a0c-4200-eb8a-9b455029f8ad"
      },
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz && tar -xf aclImdb_v1.tar.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-19 21:18:53--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz.1’\n",
            "\n",
            "aclImdb_v1.tar.gz.1 100%[===================>]  80.23M  5.92MB/s    in 18s     \n",
            "\n",
            "2020-06-19 21:19:11 (4.54 MB/s) - ‘aclImdb_v1.tar.gz.1’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQoG_qZKzBy1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1f08898d-a744-45ad-860f-38cb1c48cbf0"
      },
      "source": [
        "!git clone https://github.com/zemerov/greenatom_assignment.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'greenatom_assignment' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WKDZ1_F14zo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import greenatom_assignment.classifier.preproc as preproc\n",
        "import greenatom_assignment.classifier.models as models\n",
        "import greenatom_assignment.classifier.utils as utils"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDwJdlpufgcd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "4c3d0b22-6ae6-4e52-eb6f-3ccc14690d2d"
      },
      "source": [
        "!cd greenatom_assignment && git pull\n",
        "\n",
        "preproc = reload(preproc)\n",
        "models = reload(models)\n",
        "utils = reload(utils)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects:   9% (1/11)\u001b[K\rremote: Counting objects:  18% (2/11)\u001b[K\rremote: Counting objects:  27% (3/11)\u001b[K\rremote: Counting objects:  36% (4/11)\u001b[K\rremote: Counting objects:  45% (5/11)\u001b[K\rremote: Counting objects:  54% (6/11)\u001b[K\rremote: Counting objects:  63% (7/11)\u001b[K\rremote: Counting objects:  72% (8/11)\u001b[K\rremote: Counting objects:  81% (9/11)\u001b[K\rremote: Counting objects:  90% (10/11)\u001b[K\rremote: Counting objects: 100% (11/11)\u001b[K\rremote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects:  25% (1/4)\u001b[K\rremote: Compressing objects:  50% (2/4)\u001b[K\rremote: Compressing objects:  75% (3/4)\u001b[K\rremote: Compressing objects: 100% (4/4)\u001b[K\rremote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 6 (delta 2), reused 6 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  16% (1/6)   \rUnpacking objects:  33% (2/6)   \rUnpacking objects:  50% (3/6)   \rUnpacking objects:  66% (4/6)   \rUnpacking objects:  83% (5/6)   \rUnpacking objects: 100% (6/6)   \rUnpacking objects: 100% (6/6), done.\n",
            "From https://github.com/zemerov/greenatom_assignment\n",
            "   6774e35..4ab719a  master     -> origin/master\n",
            "Updating 6774e35..4ab719a\n",
            "Fast-forward\n",
            " README.md            | 11 \u001b[32m+++++++++\u001b[m\u001b[31m--\u001b[m\n",
            " classifier/models.py | 19 \u001b[32m++++++++++\u001b[m\u001b[31m---------\u001b[m\n",
            " classifier/utils.py  |  2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 3 files changed, 20 insertions(+), 12 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6HdnBOjAFK0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4a0b21f0-b636-4d85-8b5b-7b25638ac850"
      },
      "source": [
        "!ls  # You have to see aclImdb directory"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb\t\t   aclImdb_v1.tar.gz.1\t sample_data\n",
            "aclImdb_v1.tar.gz  greenatom_assignment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5OcpnnqIZcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = preproc.ManualTokenizer()\n",
        "\n",
        "train = []\n",
        "test = []\n",
        "\n",
        "for current_dir in ['aclImdb/train/pos/', 'aclImdb/train/neg/']:\n",
        "    for text, score in tokenizer.get_tokens_and_score(current_dir):\n",
        "        train.append((text, score))\n",
        "\n",
        "for current_dir in ['aclImdb/test/pos/', 'aclImdb/test/neg/']:\n",
        "    for text, score in tokenizer.get_tokens_and_score(current_dir):\n",
        "        test.append((text, score))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj7jRNz-Jnv-",
        "colab_type": "text"
      },
      "source": [
        "### Build token mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRad-XnhKWuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_train = np.array(train)\n",
        "np_test = np.array(test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaYJziyPJNKy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a3f49302-582b-4ada-e559-3070ba8729f2"
      },
      "source": [
        "vocab = preproc.Vocabulary(special_tokens=['END', 'BEGIN', \"PAD\", 'UNK'])\n",
        "\n",
        "vocab.fit(np.concatenate([np_train[:, 0], np_test[:, 0]]), min_count=7)\n",
        "\n",
        "print(\"vocab size:\", len(vocab))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 35940\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCdE0_rGMWPf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "9f13019e-fc02-4246-fd33-d38a03a51126"
      },
      "source": [
        "vocab.counter.most_common(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 663905),\n",
              " ('and', 320719),\n",
              " ('a', 320574),\n",
              " ('of', 288484),\n",
              " ('to', 266931),\n",
              " ('is', 210514),\n",
              " ('in', 185063),\n",
              " ('it', 154907),\n",
              " ('i', 152115),\n",
              " ('this', 149904)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz-u6F4eaG-1",
        "colab_type": "text"
      },
      "source": [
        "### Create dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcLl3MMjNRJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = utils.Dataset(train, vocab, overfit_size=1200)\n",
        "test_dataset = utils.Dataset(test, vocab)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ioh62RRvZ285",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3b828172-2a2b-4f92-ab28-516265bfd2d4"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "PAD_TOKEN = train_dataset.vocab([['PAD']])[0][0]\n",
        "\n",
        "print('PAD TOKEN {}; BATCH SIZE {}'.format(PAD_TOKEN, BATCH_SIZE))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=utils.Padder(pad_symbol=PAD_TOKEN))\n",
        "val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=utils.Padder(pad_symbol=PAD_TOKEN))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PAD TOKEN 2; BATCH SIZE 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5HrlSwOae_A",
        "colab_type": "text"
      },
      "source": [
        "### Train models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L5gm8w2aXM2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "96d9f6c5-f6b2-4f87-8fca-86b62b4009d1"
      },
      "source": [
        "embedding_dim = 256\n",
        "hidden_size = 128\n",
        "lr = 10e-3\n",
        "\n",
        "num_epoch = 3\n",
        "batch_size = 64\n",
        "\n",
        "model = models.GRU(len(vocab.i2t), embedding_dim, hidden_size).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.NLLLoss(ignore_index=PAD_TOKEN)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-692ef3da072c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi2t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPAD_TOKEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhCekch5bV7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c00fa16d-79fe-4aa6-96d3-5357b3b80c5d"
      },
      "source": [
        "for x, y in train_loader:\n",
        "    print(x.shape)\n",
        "    print(y)\n",
        "    break"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 970])\n",
            "[tensor([4.]), tensor([8.]), tensor([10.]), tensor([8.]), tensor([3.]), tensor([8.]), tensor([3.]), tensor([8.]), tensor([1.]), tensor([7.]), tensor([10.]), tensor([1.]), tensor([10.]), tensor([8.]), tensor([9.]), tensor([10.]), tensor([2.]), tensor([10.]), tensor([1.]), tensor([9.]), tensor([3.]), tensor([10.]), tensor([1.]), tensor([1.]), tensor([8.]), tensor([4.]), tensor([3.]), tensor([7.]), tensor([4.]), tensor([7.]), tensor([7.]), tensor([1.]), tensor([1.]), tensor([9.]), tensor([7.]), tensor([10.]), tensor([9.]), tensor([9.]), tensor([3.]), tensor([3.]), tensor([7.]), tensor([10.]), tensor([4.]), tensor([3.]), tensor([7.]), tensor([1.]), tensor([10.]), tensor([10.]), tensor([1.]), tensor([8.]), tensor([4.]), tensor([1.]), tensor([8.]), tensor([4.]), tensor([2.]), tensor([10.]), tensor([1.]), tensor([4.]), tensor([9.]), tensor([4.]), tensor([8.]), tensor([1.]), tensor([1.]), tensor([2.])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN9J7qtmompw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    model.train() \n",
        "    cnt = 0\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(x)\n",
        "        loss = criterion(preds, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if cnt % 50 == 0:\n",
        "          print('current loss on iter {}'.format(cnt), loss.item())\n",
        "        cnt += 1\n",
        "        \n",
        "    epoch_loss = running_loss / len(trn)\n",
        "    \n",
        "    val_loss = 0.0\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for x, y in val_iter:\n",
        "        preds = model(x)\n",
        "        loss = criterion(preds, y)\n",
        "        val_loss += loss.item()\n",
        "        \n",
        "    val_loss /= len(vld)\n",
        "    \n",
        "    print('Epoch: {}, Training Loss: {}, Validation Loss: {}'.format(epoch, epoch_loss, val_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qojPDWqXczRG",
        "colab_type": "text"
      },
      "source": [
        "### Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDDf43sQc4N1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}